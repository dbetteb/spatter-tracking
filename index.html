<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Spatter-tracking by dbetteb</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Spatter-tracking</h1>
      <h2 class="project-tagline">spatter-tracking</h2>
      <a href="https://github.com/dbetteb/spatter-tracking" class="btn">View on GitHub</a>
      <a href="https://github.com/dbetteb/spatter-tracking/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/dbetteb/spatter-tracking/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p><img src="spatter.gif" alt="Spatter detection" title="Spatter examples"></p>
<ul>
<li>
<a href="#spatter-tracking">spatter-tracking</a>
<ul>
<li>
<a href="#description">Description</a>
<ul>
<li><a href="#m-thodes-classiques">Méthodes classiques</a></li>
<li><a href="#deep-learning">Deep Learning</a></li>
</ul>
</li>
<li>
<a href="#r-f-rences">Références</a>
<ul>
<li>
<a href="#tracking-d--jectas">Tracking d'éjectas</a>
<ul>
<li>
<a href="#neural-network-based-image-segmentation-for-spatter-extraction-during-laser-based-powder-bed-fusion-processing">Neural network based image segmentation for spatter extraction during laser-based powder bed fusion processing</a>
<ul>
<li><a href="#lien">Lien</a></li>
<li><a href="#r-sum-">Résumé</a></li>
</ul>
</li>
<li>
<a href="#a-deep-learning-based-model-for-defect-detection-in-laser-powder-bed-fusion-using-in-situ-thermographic-monitoring">A deep learning-based model for defect detection in laser-powder bed fusion using in-situ thermographic monitoring</a>
<ul>
<li><a href="#lien-1">Lien</a></li>
<li><a href="#r-sum--1">Résumé</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#analyse-granulom-trique">Analyse granulométrique</a>
<ul>
<li>
<a href="#image-based-size-analysis-of-agglomerated-and-partially-sintered-particles-via-convolutional-neural-networks">Image-based size analysis of agglomerated and partially sintered particles via convolutional neural networks</a>
<ul>
<li><a href="#lien-2">Lien</a></li>
<li><a href="#r-sum--2">Résumé</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><i><a href="http://ecotrust-canada.github.io/markdown-toc/">Table of contents generated with markdown-toc</a></i></p>
<h1>
<a id="spatter-tracking" class="anchor" href="#spatter-tracking" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>spatter-tracking</h1>
<h2>
<a id="description" class="anchor" href="#description" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Description</h2>
<p>Ce site comprend un état de l'art des techniques de deep learning appliquées au tracking d'éjectas en fabrication additive par lit de poudre ainsi
que l'application de techniques de deep learning à l'analyse granulométrique des poudres.</p>
<h3>
<a id="méthodes-classiques-m-thodes-classiques" class="anchor" href="#m%C3%A9thodes-classiques-m-thodes-classiques" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Méthodes classiques {#m-thodes-classiques}</h3>
<p>ImageJ est souvent utilisé dans le monde des matériaux comme outil d'analyse d'images. Néanmoins, ImageJ (et les autres logiciels commerciaux) embarquent rarement
des fonctionnalités de deep learning car celles-ci sont rarement généralistes et difficilement réglables. Néanmoins, dans beaucoup de situations l'utilisation de technique de deep learning semblent permettre de gagner en performance par rapport à des techniques de traitement d'images plus bas niveau.</p>
<p><a href="https://i.ytimg.com/vi/2vHUbuGyoC0/maxresdefault.jpg">Example</a></p>
<h3>
<a id="deep-learning" class="anchor" href="#deep-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deep Learning</h3>
<p><a href="https://deepimagej.github.io/deepimagej/index.html">DeepImageJ</a> montre quelques applications récente de deep learning sur du traitement d'image issue des sciences des matériaux et des sciences de la vie.</p>
<h2>
<a id="références" class="anchor" href="#r%C3%A9f%C3%A9rences" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Références</h2>
<h3>
<a id="tracking-déjectas" class="anchor" href="#tracking-d%C3%A9jectas" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Tracking d'éjectas</h3>
<h4>
<a id="neural-network-based-image-segmentation-for-spatter-extraction-during-laser-based-powder-bed-fusion-processing" class="anchor" href="#neural-network-based-image-segmentation-for-spatter-extraction-during-laser-based-powder-bed-fusion-processing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Neural network based image segmentation for spatter extraction during laser-based powder bed fusion processing</h4>
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0030399220309804-gr5.jpg" alt="Spatter detection" title="Spatter detection"></p>
<h5>
<a id="lien" class="anchor" href="#lien" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lien</h5>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0030399220309804?dgcid=rss_sd_all">Zhenbiao Tan, Qihang Fang, Hui Li, Sheng Liu, Wenkang Zhu, Dekun Yang,
Neural network based image segmentation for spatter extraction during laser-based powder bed fusion processing,
Optics &amp; Laser Technology,
Volume 130,
2020,
106347,
ISSN 0030-3992</a></p>
<h5>
<a id="résumé" class="anchor" href="#r%C3%A9sum%C3%A9" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Résumé</h5>
<p>Un système de détection et de surveillance in situ des éjectas est souvent utilisée pour améliorer la qualité des produits lors de la fusion du lit de poudre par laser (LPBF). Cet article décrit une nouvelle méthode de segmentation d'images basée sur les réseaux de neurones (NN) pour l'extraction des éclaboussures avec un processus de marquage simple et des résultats de haute précision. L'utilisation d'une caméra à grande vitesse à bande d'ondes de 290-1100 nm a permis de capturer des images avec des signatures de projections plus complètes et un arrière-plan plus complexe par rapport aux études précédentes sur la fusion en lit de poudre par laser. Les approches conventionnelles de segmentation d'images ne permettent pas d'effectuer l'extraction des éclaboussures en raison de la complexité du fond. La méthode de segmentation d'images proposée, basée sur le réseau neuronal, divise les images en une grille de blocs et segmente chaque bloc en utilisant un réseau neuronal convolutif parallèle (CNN) et un réseau neuronal à seuil (TNN), ce qui permet d'extraire 80,48 % des éclaboussures en seulement 70 ms. En outre, la capacité d'extraire les éclaboussures liées à un bassin en fusion distingue la méthode de segmentation d'images proposée, basée sur le CNN, des approches de segmentation d'images conventionnelles.</p>
<h4>
<a id="a-deep-learning-based-model-for-defect-detection-in-laser-powder-bed-fusion-using-in-situ-thermographic-monitoring" class="anchor" href="#a-deep-learning-based-model-for-defect-detection-in-laser-powder-bed-fusion-using-in-situ-thermographic-monitoring" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>A deep learning-based model for defect detection in laser-powder bed fusion using in-situ thermographic monitoring</h4>
<p><img src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40964-019-00108-3/MediaObjects/40964_2019_108_Fig1_HTML.png?as=webp" alt="Detection de defaut"></p>
<h5>
<a id="lien-1" class="anchor" href="#lien-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lien</h5>
<p><a href="https://link.springer.com/article/10.1007/s40964-019-00108-3">Baumgartl, Hermann, Tomas, Josef, Buettner, Ricardo, Merkel, Markus
A deep learning-based model for defect detection in laser-powder bed fusion using in-situ thermographic monitoring,
2020, Progress in Additive Manufacturing</a></p>
<h5>
<a id="résumé-1" class="anchor" href="#r%C3%A9sum%C3%A9-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Résumé</h5>
<p>La fabrication additive de composants métalliques par fusion laser en lit de poudre est un processus très complexe, car la poudre doit être fondue et refroidie dans chaque couche pour produire une partie de la pièce. De nombreux paramètres influencent le processus d'impression ; cependant, les défauts résultant d'un réglage sous-optimal des paramètres sont généralement détectés après le processus. Pour détecter ces défauts pendant l'impression, différentes techniques de surveillance du processus, telles que la surveillance du bassin de fusion ou la surveillance infrarouge hors axe, ont été proposées. Dans ce travail, nous avons utilisé une combinaison d'imagerie thermographique hors axe comme source de données et d'architectures de réseau neuronal basées sur l'apprentissage profond, pour détecter les défauts d'impression. Pour la formation au réseau, une validation croisée avec k-plis et une validation croisée avec hold-out ont été utilisées. Grâce à ces techniques, des défauts tels que le délaminage et les éjectas peuvent être reconnus avec une précision de 96,80 %. En outre, le modèle a été évalué à l'aide de l'évaluation de la densité de calcul par couche. L'architecture est très petite et a de faibles coûts de calcul, ce qui signifie qu'elle est adaptée pour fonctionner en temps réel même sur du hardware peu puissant.</p>
<h3>
<a id="analyse-granulométrique" class="anchor" href="#analyse-granulom%C3%A9trique" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analyse granulométrique</h3>
<h4>
<a id="image-based-size-analysis-of-agglomerated-and-partially-sintered-particles-via-convolutional-neural-networks" class="anchor" href="#image-based-size-analysis-of-agglomerated-and-partially-sintered-particles-via-convolutional-neural-networks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Image-based size analysis of agglomerated and partially sintered particles via convolutional neural networks</h4>
<h5>
<a id="lien-2" class="anchor" href="#lien-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lien</h5>
<p><a href="https://www.sciencedirect.com/science/article/pii/S003259101930854X">M. Frei, F.E. Kruis,
Image-based size analysis of agglomerated and partially sintered particles via convolutional neural networks,
Powder Technology,
Volume 360,
2020,
Pages 324-336,</a></p>
<h5>
<a id="résumé-2" class="anchor" href="#r%C3%A9sum%C3%A9-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Résumé</h5>
<p>Il existe une forte demande de méthodes entièrement automatisées pour l'analyse des distributions granulométriques des particules primaires agglomérées ou frittées en raison de leur impact sur les propriétés des matériaux. C'est pourquoi une nouvelle méthode de détection de ces particules primaires, basée sur l' apprentissage profond, a été proposée et testée, ce qui rend inutile un réglage manuel des paramètres d'analyse de l'image dans les méthodes classiques.
L'entraînement des réseaux neuronaux convolutifs utilisés a été effectuée en utilisant uniquement des images synthétiques, évitant ainsi la tâche laborieuse de l'annotation manuelle et augmentant la qualité de la vérité de terrain. Néanmoins, la méthode proposée donne d'excellents résultats sur des échantillons réels de nanoparticules de silice frittée avec divers degrés de frittage et des conditions d'image variables.
En comparaison directe, la méthode proposée est nettement plus performante que deux méthodes avancées pour l'analyse granulométrique automatisée basée sur l'image (transformation de Hough et le plug-in ImageJ ParticleSizer), atteignant ainsi des performances comparables à celles d'un humain.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/dbetteb/spatter-tracking">Spatter-tracking</a> is maintained by <a href="https://github.com/dbetteb">dbetteb</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
