<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Spatter-tracking by dbetteb</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Spatter-tracking</h1>
        <p>spatter-tracking</p>

        <p class="view"><a href="https://github.com/dbetteb/spatter-tracking">View the Project on GitHub <small>dbetteb/spatter-tracking</small></a></p>


        <ul>
          <li><a href="https://github.com/dbetteb/spatter-tracking/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/dbetteb/spatter-tracking/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/dbetteb/spatter-tracking">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <p><img src="spatter.gif" alt="Spatter detection" title="Spatter examples"></p>
<ul>
<li>
<a href="#spatter-tracking">spatter-tracking</a>
<ul>
<li>
<a href="#description">Description</a>
<ul>
<li><a href="#methodes-classiques">Méthodes classiques</a></li>
<li><a href="#deep-learning">Deep Learning</a></li>
</ul>
</li>
<li>
<a href="#articles">Articles</a>
<ul>
<li>
<a href="#detection-d-ejectas--computer-vision-">Détection d'éjectas (computer vision)</a>
<ul>
<li>
<a href="#types-of-spatter-and-their-features-and-formation-mechanisms-in-laser-powder-bed-fusion-additive-manufacturing-process">Types of spatter and their features and formation mechanisms in laser powder bed fusion additive manufacturing process</a>
<ul>
<li><a href="#lien">Lien</a></li>
<li><a href="#resume">Résumé</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#detection-d-ejectas--deep-learning-">Détection d'éjectas (deep learning)</a>
<ul>
<li>
<a href="#neural-network-based-image-segmentation-for-spatter-extraction-during-laser-based-powder-bed-fusion-processing">Neural network based image segmentation for spatter extraction during laser-based powder bed fusion processing</a>
<ul>
<li><a href="#lien-1">Lien</a></li>
<li><a href="#resume-1">Résumé</a></li>
</ul>
</li>
<li>
<a href="#a-deep-learning-based-model-for-defect-detection-in-laser-powder-bed-fusion-using-in-situ-thermographic-monitoring">A deep learning-based model for defect detection in laser-powder bed fusion using in-situ thermographic monitoring</a>
<ul>
<li><a href="#lien-2">Lien</a></li>
<li><a href="#resume-2">Résumé</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#analyse-granulometrique">Analyse granulométrique</a>
<ul>
<li>
<a href="#image-based-size-analysis-of-agglomerated-and-partially-sintered-particles-via-convolutional-neural-networks">Image-based size analysis of agglomerated and partially sintered particles via convolutional neural networks</a>
<ul>
<li><a href="#lien-3">Lien</a></li>
<li><a href="#resume-3">Résumé</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><i><a href="http://ecotrust-canada.github.io/markdown-toc/">Table of contents generated with markdown-toc</a></i></p>
<h1>
<a id="spatter-tracking" class="anchor" href="#spatter-tracking" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>spatter-tracking</h1>
<h2>
<a id="description" class="anchor" href="#description" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Description</h2>
<p>Ce site comprend un état de l'art des techniques de deep learning appliquées au tracking d'éjectas en fabrication additive par lit de poudre ainsi
que l'application de techniques de deep learning à l'analyse granulométrique des poudres.</p>
<h3>
<a id="methodes-classiques" class="anchor" href="#methodes-classiques" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Methodes classiques</h3>
<p><a href="https://fr.wikipedia.org/wiki/ImageJ">ImageJ</a> (<em>Image Analysis and Processing in Java</em>) est souvent utilisé dans le monde des matériaux comme outil d'analyse d'images. Néanmoins, ImageJ (et les autres logiciels commerciaux) embarquent rarement
des fonctionnalités de deep learning car celles-ci sont rarement généralistes et difficilement réglables. Néanmoins, dans beaucoup de situations l'utilisation de technique de deep learning semble permettre de gagner en performance par rapport à des techniques de traitement d'images plus bas niveau.</p>
<p><img src="https://www.fzu.cz/~dominecf/granulo/img/particles_found.png" alt="Example"></p>
<h3>
<a id="deep-learning" class="anchor" href="#deep-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deep Learning</h3>
<p><a href="https://deepimagej.github.io/deepimagej/index.html">DeepImageJ</a> montre quelques applications récente de deep learning sur du traitement d'image issue des sciences des matériaux et des sciences de la vie.</p>
<p><img src="https://deepimagej.github.io/deepimagej/images/deepimagej_logo.png" alt="DeepImageJ"></p>
<h2>
<a id="articles" class="anchor" href="#articles" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Articles</h2>
<h3>
<a id="detection-dejectas-computer-vision" class="anchor" href="#detection-dejectas-computer-vision" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Detection d'ejectas (computer vision)</h3>
<h4>
<a id="types-of-spatter-and-their-features-and-formation-mechanisms-in-laser-powder-bed-fusion-additive-manufacturing-process" class="anchor" href="#types-of-spatter-and-their-features-and-formation-mechanisms-in-laser-powder-bed-fusion-additive-manufacturing-process" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Types of spatter and their features and formation mechanisms in laser powder bed fusion additive manufacturing process</h4>
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2214860420308101-gr6.jpg" alt="Spatter types"></p>
<h5>
<a id="lien" class="anchor" href="#lien" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lien</h5>
<p><a href="https://www.sciencedirect.com/science/article/pii/S2214860420308101">Zachary A. Young, Qilin Guo, Niranjan D. Parab, Cang Zhao, Minglei Qu, Luis I. Escano, Kamel Fezzaa, Wes Everhart, Tao Sun, Lianyi Chen,
Types of spatter and their features and formation mechanisms in laser powder bed fusion additive manufacturing process,
Additive Manufacturing,
2020,
101438,
ISSN 2214-8604,
https://doi.org/10.1016/j.addma.2020.101438</a></p>
<h5>
<a id="resume" class="anchor" href="#resume" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resume</h5>
<p>En fabrication additives par fusion laser sur lit de poudre (LPBF), les éjectas provoquent la formation de défauts, la redistribution non-uniforme de la poudre et la contamination du processus. Il est essentiel de distinguer les différents types d'éjectas et de comprendre leurs caractéristiques et leurs mécanismes de formation. Ce travail révèle les caractéristiques et les mécanismes de formation de cinq types uniques d'éjectas au cours du processus de LPBF par imagerie radiographique in situ à haute vitesse et haute énergie. Les éjectas observés pendant le test LPBF sont quantifiés par leur vitesse, leur taille et leur direction. Des caractéristiques quantifiables distinctes pour chaque type d'éjectas sont identifiées. Les effets de la puissance du laser, de la vitesse de balayage et de la pression ambiante sur la formation et les caractéristiques des éjectas sont mis en évidence. Une carte de formation des éjectas pour l'alliage AlSi10Mg est établie.</p>
<h3>
<a id="detection-dejectas-deep-learning" class="anchor" href="#detection-dejectas-deep-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Detection d'ejectas (deep learning)</h3>
<h4>
<a id="neural-network-based-image-segmentation-for-spatter-extraction-during-laser-based-powder-bed-fusion-processing" class="anchor" href="#neural-network-based-image-segmentation-for-spatter-extraction-during-laser-based-powder-bed-fusion-processing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Neural network based image segmentation for spatter extraction during laser-based powder bed fusion processing</h4>
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0030399220309804-gr5.jpg" alt="Spatter detection" title="Spatter detection"></p>
<h5>
<a id="lien-1" class="anchor" href="#lien-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lien</h5>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0030399220309804?dgcid=rss_sd_all">Zhenbiao Tan, Qihang Fang, Hui Li, Sheng Liu, Wenkang Zhu, Dekun Yang,
Neural network based image segmentation for spatter extraction during laser-based powder bed fusion processing,
Optics &amp; Laser Technology,
Volume 130,
2020,
106347,
ISSN 0030-3992</a></p>
<h5>
<a id="resume-1" class="anchor" href="#resume-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resume</h5>
<p>Un système de détection et de surveillance in situ des éjectas est souvent utilisée pour améliorer la qualité des produits lors de la fusion du lit de poudre par laser (LPBF). Cet article décrit une nouvelle méthode de segmentation d'images basée sur les réseaux de neurones (NN) pour l'extraction des éclaboussures avec un processus de marquage simple et des résultats de haute précision. L'utilisation d'une caméra à grande vitesse à bande d'ondes de 290-1100 nm a permis de capturer des images avec des signatures de projections plus complètes et un arrière-plan plus complexe par rapport aux études précédentes sur la fusion en lit de poudre par laser. Les approches conventionnelles de segmentation d'images ne permettent pas d'effectuer l'extraction des éclaboussures en raison de la complexité du fond. La méthode de segmentation d'images proposée, basée sur le réseau neuronal, divise les images en une grille de blocs et segmente chaque bloc en utilisant un réseau neuronal convolutif parallèle (CNN) et un réseau neuronal à seuil (TNN), ce qui permet d'extraire 80,48 % des éclaboussures en seulement 70 ms. En outre, la capacité d'extraire les éclaboussures liées à un bassin en fusion distingue la méthode de segmentation d'images proposée, basée sur le CNN, des approches de segmentation d'images conventionnelles.</p>
<h4>
<a id="a-deep-learning-based-model-for-defect-detection-in-laser-powder-bed-fusion-using-in-situ-thermographic-monitoring" class="anchor" href="#a-deep-learning-based-model-for-defect-detection-in-laser-powder-bed-fusion-using-in-situ-thermographic-monitoring" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>A deep learning-based model for defect detection in laser-powder bed fusion using in-situ thermographic monitoring</h4>
<p><img src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40964-019-00108-3/MediaObjects/40964_2019_108_Fig1_HTML.png?as=webp" alt="Detection de defaut"></p>
<h5>
<a id="lien-2" class="anchor" href="#lien-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lien</h5>
<p><a href="https://link.springer.com/article/10.1007/s40964-019-00108-3">Baumgartl, Hermann, Tomas, Josef, Buettner, Ricardo, Merkel, Markus
A deep learning-based model for defect detection in laser-powder bed fusion using in-situ thermographic monitoring,
2020, Progress in Additive Manufacturing</a></p>
<h5>
<a id="resume-2" class="anchor" href="#resume-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resume</h5>
<p>La fabrication additive de composants métalliques par fusion laser en lit de poudre est un processus très complexe, car la poudre doit être fondue et refroidie dans chaque couche pour produire une partie de la pièce. De nombreux paramètres influencent le processus d'impression ; cependant, les défauts résultant d'un réglage sous-optimal des paramètres sont généralement détectés après le processus. Pour détecter ces défauts pendant l'impression, différentes techniques de surveillance du processus, telles que la surveillance du bassin de fusion ou la surveillance infrarouge hors axe, ont été proposées. Dans ce travail, nous avons utilisé une combinaison d'imagerie thermographique hors axe comme source de données et d'architectures de réseau neuronal basées sur l'apprentissage profond, pour détecter les défauts d'impression. Pour la formation au réseau, une validation croisée avec k-plis et une validation croisée avec hold-out ont été utilisées. Grâce à ces techniques, des défauts tels que le délaminage et les éjectas peuvent être reconnus avec une précision de 96,80 %. En outre, le modèle a été évalué à l'aide de l'évaluation de la densité de calcul par couche. L'architecture est très petite et a de faibles coûts de calcul, ce qui signifie qu'elle est adaptée pour fonctionner en temps réel même sur du hardware peu puissant.</p>
<h3>
<a id="analyse-granulometrique" class="anchor" href="#analyse-granulometrique" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analyse granulometrique</h3>
<h4>
<a id="image-based-size-analysis-of-agglomerated-and-partially-sintered-particles-via-convolutional-neural-networks" class="anchor" href="#image-based-size-analysis-of-agglomerated-and-partially-sintered-particles-via-convolutional-neural-networks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Image-based size analysis of agglomerated and partially sintered particles via convolutional neural networks</h4>
<h5>
<a id="lien-3" class="anchor" href="#lien-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Lien</h5>
<p><a href="https://www.sciencedirect.com/science/article/pii/S003259101930854X">M. Frei, F.E. Kruis,
Image-based size analysis of agglomerated and partially sintered particles via convolutional neural networks,
Powder Technology,
Volume 360,
2020,
Pages 324-336,</a></p>
<h5>
<a id="resume-3" class="anchor" href="#resume-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resume</h5>
<p>Il existe une forte demande de méthodes entièrement automatisées pour l'analyse des distributions granulométriques des particules primaires agglomérées ou frittées en raison de leur impact sur les propriétés des matériaux. C'est pourquoi une nouvelle méthode de détection de ces particules primaires, basée sur l' apprentissage profond, a été proposée et testée, ce qui rend inutile un réglage manuel des paramètres d'analyse de l'image dans les méthodes classiques.
L'entraînement des réseaux neuronaux convolutifs utilisés a été effectuée en utilisant uniquement des images synthétiques, évitant ainsi la tâche laborieuse de l'annotation manuelle et augmentant la qualité de la vérité de terrain. Néanmoins, la méthode proposée donne d'excellents résultats sur des échantillons réels de nanoparticules de silice frittée avec divers degrés de frittage et des conditions d'image variables.
En comparaison directe, la méthode proposée est nettement plus performante que deux méthodes avancées pour l'analyse granulométrique automatisée basée sur l'image (transformation de Hough et le plug-in ImageJ ParticleSizer), atteignant ainsi des performances comparables à celles d'un humain.</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/dbetteb">dbetteb</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
